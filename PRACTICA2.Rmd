---
title: 'Pràctica 2: Neteja i validació de les dades'
author: "Carlos Pérez Martín i Oscar Fernandez Castro"
date: "18 de mayo de 2019"
output: html_document
---

```{r setup, include=FALSE}
data_train<- read.csv('C:/Users/vodsk/Desktop/UOC/Topologia i cicle de vida de les dades/PRACTICA2/kaggle-titanic-master/input/train.csv',header=T,sep=",", encoding = "UTF-8")
str(data_train)
summary(data_train)
```

<H3>1. Descripció del dataset. Perquè és important i quina pregunta/problema pretén respondre?</H3>

Els datasets obtingut de https://www.kaggle.com, contenen informació sobre els passatgers del titanic. Des de dades demogràfiques dels passatgers fins a si van sobreviure o no al viatge.

En total hi han 3 datatsets:

- train: 12 atributs amb 891 files.
- test: 11 atributs amb 418 files.
- gender_submission: 2 atributs amb 418 files.

Els tres datasets formen un conjunt de prova i d'entrenament.

Els atributs que tenim en els diferents datasets són:

- Survival: Supervivent (0 = No, 1 = Si)
- Pclass: Classe del passatger (1= 1era, 2 = 2ona, 3 = 3ra)
- Name: Nom
- Sex: Sexe (female, male)
- Age: edad
- Sibsp: Nombre de familiars
- Parch: Nombre de pares/fills embarcats
- Ticket: Número d'entrada
- Fare: Tarifa
- Cabin: cabina
- Embarked: Embarcat (C = Cherbourg, Q = Queenstown, S = Southampton)

La pregunta que volem respondre, és quins són els factors més determinants que influeixen en la taxa de supervivència del passatge. Quins atributs tenen un impacte més elevat? (sexe, classe, edat, etc). Per això s'utilitzaran mètodes de regressió per avaluar les relacions entre atributs.

<H3>2. Integració i selecció de les dades d’interès a analitzar.</H3>

Per començar unificarem els tres datasets en un per fer la neteja de les dades. Després en cas necessari ja se separaran de nou en conjunts de prova i d'entrenament.

```{r}
data_test<- read.csv('C:/Users/vodsk/Desktop/UOC/Topologia i cicle de vida de les dades/PRACTICA2/kaggle-titanic-master/input/test.csv',header=T,sep=",", encoding = "UTF-8")
data_sub<-read.csv('C:/Users/vodsk/Desktop/UOC/Topologia i cicle de vida de les dades/PRACTICA2/kaggle-titanic-master/input/gender_submission.csv',header=T,sep=",", encoding = "UTF-8")

#unifiquem el dataset de test amb els seus resultats
data_test <- merge(data_test,data_sub, by="PassengerId")

#juntem les files dels datasets de train i test
data<-rbind(data_train, data_test)
```

Ara ja tenim el dataset complet amb 1309 registres i 12 atributs.

Volem analitzar el nombre més gran d'atributs possibles, però a simple vista, ja podem dir que els atributs Name i PassangerId, no ens aporten informació, així que els eliminarem.

Agafarem l'atribut survived com a referència i utilitzant diferents mètodes estadístics, veurem quin impacte tenen els altres atributs sobre aquest.


<H3>3. Neteja de les dades.</H3>

Al fer una revisió del tipus de dades, veiem que l'atribut Pclass és de tipus enter, quan hauria de ser de tipus factor.
En el cas de l'atribut Survived també és de tipus enter quan hauria de ser binari. L'atribut survived es podría convertir a un atribut de tipus lògic (true/false)

Tipus de dades abans de la conversió
PassengerId    Survived      Pclass        Name         Sex         Age       SibSp       Parch      Ticket 
  "integer"   "integer"   "integer"    "factor"    "factor"   "numeric"   "integer"   "integer"    "factor" 
       Fare       Cabin    Embarked 
"character"    "factor"    "factor" 

Tipus de dades desprès de la conversió
PassengerId    Survived      Pclass        Name         Sex         Age       SibSp       Parch      Ticket 
  "integer"       "raw"    "factor"    "factor"    "factor"   "numeric"   "integer"   "integer"    "factor" 
       Fare       Cabin    Embarked 
"character"    "factor"    "factor" 

```{r}
sapply(data,class)
data$Pclass<-as.factor(data$Pclass)
#data$Survived<-as.raw(data$Survived)
data$Survived<-as.logical(data$Survived)
sapply(data,class)
```


<H3>3.1. Les dades contenen zeros o elements buits? Com gestionaries aquests casos?</H3>

Busquem en tots els atributs els valors NA i buits.

Valors NA
PassengerId    Survived      Pclass        Name         Sex         Age       SibSp       Parch      Ticket 
          0           0           0           0           0         263           0           0           0 
       Fare       Cabin    Embarked 
          1           0           0 
          
Valors buits
PassengerId    Survived      Pclass        Name         Sex         Age       SibSp       Parch      Ticket 
          0           0           0           0           0           0           0           0           0 
       Fare       Cabin    Embarked 
          0        1014           2 
          

```{r}
sapply(data, function(x) sum(is.na(x)))
sapply(data, function(x) sum(x==""))
```

L'atribut Age té 263 casos amb valor NA, i l'atribut Embarked 2 casos de valor buit. En cada cas utilitzarem una tècnica diferent, per l'atribut age, substituirem els valors NA's per la mediana (molt similar a la mitjana), i en el cas de l'atribut embarked els modificarem per l'atribut majoritari.

Una altra opció pels valors buits de "Age". Substituir els valors NA segons k-Nearest Neighbors (kNN)

```{r include=FALSE}
library(VIM)
```


```{r}

data$Age <- kNN(data)$Age
```
Un cop modificat el valor d'Age, volem veure si aquesta modificació ha tingut un gran impacte. Creem un dataframe nou, amb les dades sense modificar, y es comparen les dades modificades amb la mitjana amb les dades originals. Sería correcte aquest mètode??


```{r}
data2<-rbind(data_train, data_test)
par(mfrow=c(1,2))
hist(data$Age, freq=F, main="Age: values NA with mean",col='darkgreen', ylim=c(0,0.04))
hist(data2$Age, freq=F, main="Age: Original Data",col='lightgreen', ylim=c(0,0.04))
```


```{r}

data$Embarked[data$Embarked==""]<- "S"
data$Age[is.na(data$Age)]<-28 #mediana = 28

```

En el cas de l'atribut cabina (cabin) tenim 1014 registres buits dels 1309 del dataset. A més els valors que tenim estan molt fragmentats. En aquestes circumstancies l'atibut cabina no ens aportarà informació rellevant o fiable, així que l'eliminarem en la part de selecció d'atributs (apartat 4.1).

L'atribut tarifa (fare) conté un valor NA. En aquest cas el modifiquem i li posem la mitjana. Per a no pasarli un valor fixe, modifiquem la forma de assignar la mitjana al valor nul. Calculo la mitjana de la variable Fare, excloent al càlcul els valors NA.

```{r}
data$Fare[is.na(data$Fare)] <- mean(data$Fare, na.rm=TRUE)
```



<H3>3.2. Identificació i tractament de valors extrems.</H3>

Busquem valors extrems en els atributs númerics. Comencem amb un mètode molt visualt, el blotpox.

```{r}

par(mfrow=c(2,2))
for(i in 2:ncol(data)) #ignorem PassengerId
{
  if ((is.numeric(data[,i]))||(is.integer(data[,i])))
  {
    boxplot(data[,i], main = colnames(data)[i], width=100) 
  }
  
}

```


```{r}
boxplot.stats(data$Age)$out
boxplot.stats(data$SibSp)$out
boxplot.stats(data$Parch)$out
boxplot.stats(data$Fare)$out
```

Els valors dels outliers mostrar pel boxplot de l'atribut edat són valors coherents, no els considerem outliers, ja que es mostren forà del gràfic per la concentració de valors entre els 20 i 30 anys.

El mateix es pot dir pels atributs SibSp i Parch, la majoria de regsitres tenen valor 0, i fa que el boxplot estigui molt comprimit en aquest interval. Tenir 8 fills és un valor elevat, pero no es pot considerar irreal.

En el cas de l'atribut Fare revisarem amb més detall els seus valors depenent de l'atribut Pclass, que clarament està relacionat.

```{r}
par(mfrow=c(2,2))
boxplot(data$Fare[data$Pclass==1], main = "Fare - Pclass=1", width=100) 
boxplot(data$Fare[data$Pclass==2], main = "Fare - Pclass=2", width=100) 
boxplot(data$Fare[data$Pclass==3], main = "Fare - Pclass=3", width=100) 

summary(data$Fare[data$Pclass==1])
summary(data$Fare[data$Pclass==2])
summary(data$Fare[data$Pclass==3])
```


<H3>4. Anàlisi de les dades.</H3>
<H3>4.1. Selecció dels grups de dades que es volen analitzar/comparar (planificació dels anàlisis a aplicar).</H3>

Com ja hem comentat anteriorment, tenim atributs que no aporten cap informació útil (PassengerId, Name), i d'altres que tenen masses registres buits perquè puguin aportar informació valida (Cabin). Els eliminem.

```{r}
data<-data[ , -which(names(data) %in% c("PassengerId","Name","Cabin"))]
```

<H3>4.2. Comprovació de la normalitat i homogeneïtat de la variància.</H3>

Per comprobar la normailitat de les dades fem servir un anàlisi visual (qqplot i histograma) i el test shapiro-wilk.

```{r}

par(mfrow=c(2,2))
for(i in 1:ncol(data))
{
  if ((is.numeric(data[,i]))|(is.integer(data[,i])))
  {
    qqnorm(data[,i], main = colnames(data)[i]);qqline(data[,i])
    hist(data[,i], main = colnames(data)[i])
  }
}

```

Apliquem l'algoritme de shapiro-wilk.

```{r}
shapiro.test(data$Age)
shapiro.test(data$SibSp)
shapiro.test(data$Parch)
shapiro.test(data$Fare)
```

Els tests de shapiro-wilk ens retornen un p-valor inferior a 0.05 per tant no es compleix la hipòtesis nul·la i per tant les dades no segueixen una distribució normal.

Tant els gràfics com el test de shapiro-wilk, ens indiquen que les dades no segueixen una distribució normal. Però sabem pel que diu el teorema del límit central, que si tenim més de 30 distribucions, es pot aproximar a una distribució normal de mitja 0 i desviació estàndard 1.

La neteja de dades realitzada sobre l'atribut edat, ha influït de manera significativa en la distribució de les dades. Tal com es pot veure en els gràfics.

<H3>4.3. Aplicació de proves estadístiques per comparar els grups de dades. En funció de les dades i de l’objectiu de l’estudi, aplicar proves de contrast d’hipòtesis,
correlacions, regressions, etc. Aplicar almenys tres mètodes d’anàlisi diferents. </H3>

Es crea un model per a predir si una persona sobreviurà o no
```{r}
train<-data[1:891,]
test<-data[892:1309,]

#install.packages("C50",dependencies=TRUE)
library(C50)
vars<-c("Pclass","Sex","Age","SibSp","Parch","Fare")
str(data[c(vars,"Survived")])
train$Survived<-as.factor(train$Survived)
tree_mod <-C5.0(x=train[,vars],y=train$Survived)
summary(tree_mod)
p1<-predict(tree_mod,test)
summary(p1)
table(test$Survived,Predicted=p1)
plot(tree_mod)
plot(tree_mod,type="simple")
```



```{r}
train<-data[1:891,]
test<-data[892:1309,]
modelA<-lm(train$Survived ~ train$Sex + train$Age)
modelB<-lm(train$Survived ~ train$Sex + train$Age + train$Pclass)
modelC<-lm(train$Survived ~ train$Sex + train$Age + train$Pclass + train$SibSp)
modelD<-lm(train$Survived ~ train$Sex + train$Age + train$Pclass + train$SibSp + train$Embarked)
modelE<-lm(train$Survived ~ train$Sex + train$Age + train$Pclass + train$SibSp + train$Embarked + train$Fare)
modelF<-lm(train$Survived ~ train$Sex + train$Age + train$Pclass + train$SibSp + train$Embarked + train$Fare + train$Parch)

taulaReg<-matrix(c('A',summary(modelA)$r.squared,
                    'B',summary(modelB)$r.squared,
                    'C',summary(modelC)$r.squared,
                    'D',summary(modelD)$r.squared,
                    'E',summary(modelE)$r.squared,
                    'F',summary(modelF)$r.squared), ncol=2, byrow = TRUE)

colnames(taulaReg)<-c("Model","R^2")
taulaReg

```


```{r}
summary(modelF)

prediccio<-predict(modelF, test, type="response")
#prediccio
#table(test$Survived,prediccio>0.5)
```



