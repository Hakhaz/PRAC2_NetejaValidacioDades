---
title: 'Pràctica 2: Neteja i validació de les dades'
author: "Carlos Pérez Martín i Oscar Fernandez Castro"
date: "18 de mayo de 2019"
output: html_document
---

```{r setup, include=FALSE}
data_train<- read.csv('C:/Users/vodsk/Desktop/UOC/Topologia i cicle de vida de les dades/PRACTICA2/kaggle-titanic-master/input/train.csv',header=T,sep=",", encoding = "UTF-8")
str(data_train)
summary(data_train)
```

<H3>1. Descripció del dataset. Perquè és important i quina pregunta/problema pretén respondre?</H3>

Els datasets obtingut de https://www.kaggle.com, contenen informació sobre els passatgers del titanic. Des de dades demogràfiques dels passatgers fins a si van sobreviure o no al viatge.

En total hi han 3 datatsets:

- train: 12 atributs amb 891 files.
- test: 11 atributs amb 418 files.
- gender_submission: 2 atributs amb 418 files.

Els tres datasets formen un conjunt de prova i d'entrenament.

Els atributs que tenim en els diferents datasets són:

- Survival: Supervivent (0 = No, 1 = Si)
- Pclass: Classe del passatger (1= 1era, 2 = 2ona, 3 = 3ra)
- Name: Nom
- Sex: Sexe (female, male)
- Age: edad
- Sibsp: Nombre de familiars
- Parch: Nombre de pares/fills embarcats
- Ticket: Número d'entrada
- Fare: Tarifa
- Cabin: cabina
- Embarked: Embarcat (C = Cherbourg, Q = Queenstown, S = Southampton)

La pregunta que volem respondre, és quins són els factors més determinants que influeixen en la taxa de supervivència del passatge. Quins atributs tenen un impacte més elevat? (sexe, classe, edat, etc). Per això s'utilitzaran mètodes de regressió per avaluar les relacions entre atributs.

<H3>2. Integració i selecció de les dades d’interès a analitzar.</H3>

Per començar unificarem els tres datasets en un per fer la neteja de les dades. Després en cas necessari ja se separaran de nou en conjunts de prova i d'entrenament.

```{r}
data_test<- read.csv('C:/Users/vodsk/Desktop/UOC/Topologia i cicle de vida de les dades/PRACTICA2/kaggle-titanic-master/input/test.csv',header=T,sep=",", encoding = "UTF-8")
data_sub<-read.csv('C:/Users/vodsk/Desktop/UOC/Topologia i cicle de vida de les dades/PRACTICA2/kaggle-titanic-master/input/gender_submission.csv',header=T,sep=",", encoding = "UTF-8")

#unifiquem el dataset de test amb els seus resultats
data_test <- merge(data_test,data_sub, by="PassengerId")

#juntem les files dels datasets de train i test
data<-rbind(data_train, data_test)
```

Ara ja tenim el dataset complet amb 1309 registres i 12 atributs.

Volem analitzar el nombre més gran d'atributs possibles, però a simple vista, ja podem dir que els atributs Name i PassangerId, no ens aporten informació, així que els eliminarem.

Agafarem l'atribut survived com a referència i utilitzant diferents mètodes estadístics, veurem quin impacte tenen els altres atributs sobre aquest.


<H3>3. Neteja de les dades.</H3>

Al fer una revisió del tipus de dades, veiem que l'atribut Pclass és de tipus enter, quan hauria de ser de tipus factor.
En el cas de l'atribut Survived també és de tipus enter quan hauria de ser binari. L'atribut survived es podría convertir a un atribut de tipus lògic (true/false)

Tipus de dades abans de la conversió
```{r}
sapply(data,class)
```
Tipus de dades desprès de la converrsió
```{r}
data$Pclass<-as.factor(data$Pclass)
#data$Survived<-as.raw(data$Survived)
data$Survived<-as.logical(data$Survived)
sapply(data,class)
```


<H3>3.1. Les dades contenen zeros o elements buits? Com gestionaries aquests casos?</H3>

Busquem en tots els atributs els valors NA i buits.
          
Valors NA
```{r}
sapply(data, function(x) sum(is.na(x)))
```

Valors buits
```{r}
sapply(data, function(x) sum(x==""))
```

L'atribut Age té 263 casos amb valor NA, i l'atribut Embarked 2 casos de valor buit. En cada cas utilitzarem una tècnica diferent, per l'atribut age, substituirem els valors NA segons k-Nearest Neighbors (kNN), i en el cas de l'atribut embarked els modificarem per l'atribut majoritari.

```{r include=FALSE}
library(VIM)
```

```{r}
data$Age <- kNN(data)$Age
data$Embarked[data$Embarked==""]<- "S"
#data$Age[is.na(data$Age)]<-28 #mediana = 28
```
Un cop modificat el valor d'Age, volem veure si aquesta modificació ha tingut un gran impacte. Creem un dataframe nou, amb les dades sense modificar, y es comparen les dades modificades amb la mitjana amb les dades originals.

```{r}
data2<-rbind(data_train, data_test)
par(mfrow=c(1,2))
hist(data$Age, freq=F, main="Age: values NA with mean",col='darkgreen', ylim=c(0,0.04))
hist(data2$Age, freq=F, main="Age: Original Data",col='lightgreen', ylim=c(0,0.04))
```

En el cas de l'atribut cabina (cabin) tenim 1014 registres buits dels 1309 del dataset. A més els valors que tenim estan molt fragmentats. En aquestes circumstancies l'atibut cabina no ens aportarà informació rellevant o fiable, així que l'eliminarem en la part de selecció d'atributs (apartat 4.1).

L'atribut tarifa (fare) conté un valor NA. En aquest cas el modifiquem i li posem la mitjana. Per a no pasarli un valor fixe, modifiquem la forma de assignar la mitjana al valor nul. Calculo la mitjana de la variable Fare, excloent al càlcul els valors NA.

```{r}
data$Fare[is.na(data$Fare)] <- mean(data$Fare, na.rm=TRUE)
```



<H3>3.2. Identificació i tractament de valors extrems.</H3>

Busquem valors extrems en els atributs númerics. Comencem amb un mètode molt visualt, el blotpox.

```{r}

par(mfrow=c(2,2))
for(i in 2:ncol(data)) #ignorem PassengerId
{
  if ((is.numeric(data[,i]))||(is.integer(data[,i])))
  {
    boxplot(data[,i], main = colnames(data)[i], width=100) 
  }
  
}

```


```{r}
boxplot.stats(data$Age)$out
boxplot.stats(data$SibSp)$out
boxplot.stats(data$Parch)$out
boxplot.stats(data$Fare)$out
```

Els valors dels outliers mostrar pel boxplot de l'atribut edat són valors coherents, no els considerem outliers, ja que es mostren forà del gràfic per la concentració de valors entre els 20 i 30 anys.

El mateix es pot dir pels atributs SibSp i Parch, la majoria de regsitres tenen valor 0, i fa que el boxplot estigui molt comprimit en aquest interval. Tenir 8 fills és un valor elevat, pero no es pot considerar irreal.

En el cas de l'atribut Fare revisarem amb més detall els seus valors depenent de l'atribut Pclass, que clarament està relacionat.

```{r}
par(mfrow=c(2,2))
boxplot(data$Fare[data$Pclass==1], main = "Fare - Pclass=1", width=100) 
boxplot(data$Fare[data$Pclass==2], main = "Fare - Pclass=2", width=100) 
boxplot(data$Fare[data$Pclass==3], main = "Fare - Pclass=3", width=100) 

summary(data$Fare[data$Pclass==1])
summary(data$Fare[data$Pclass==2])
summary(data$Fare[data$Pclass==3])
```


<H3>4. Anàlisi de les dades.</H3>
<H3>4.1. Selecció dels grups de dades que es volen analitzar/comparar (planificació dels anàlisis a aplicar).</H3>

Com ja hem comentat anteriorment, tenim atributs que no aporten cap informació útil (PassengerId, Name), i d'altres que tenen masses registres buits perquè puguin aportar informació valida (Cabin). Els eliminem.

```{r}
data<-data[ , -which(names(data) %in% c("PassengerId","Name","Cabin"))]
```

Es vol comparar quins pesos tenen els diferents atributs sobre la supervivenvia o no d'un individu, quins són els factors que més influeixen.

<H3>4.2. Comprovació de la normalitat i homogeneïtat de la variància.</H3>

Per comprobar la normailitat de les dades fem servir un anàlisi visual (qqplot i histograma) i el test shapiro-wilk.

```{r}

par(mfrow=c(2,2))
for(i in 1:ncol(data))
{
  if ((is.numeric(data[,i]))|(is.integer(data[,i])))
  {
    qqnorm(data[,i], main = colnames(data)[i]);qqline(data[,i])
    hist(data[,i], main = colnames(data)[i])
  }
}

```

Apliquem l'algoritme de shapiro-wilk.

```{r}
shapiro.test(data$Age)
shapiro.test(data$SibSp)
shapiro.test(data$Parch)
shapiro.test(data$Fare)
```

Els tests de shapiro-wilk ens retornen un p-valor inferior a 0.05 per tant no es compleix la hipòtesis nul·la i per tant les dades no segueixen una distribució normal.

Tant els gràfics com el test de shapiro-wilk, ens indiquen que les dades no segueixen una distribució normal. Però sabem pel que diu el teorema del límit central, que si tenim més de 30 distribucions, es pot aproximar a una distribució normal de mitja 0 i desviació estàndard 1.

La neteja de dades realitzada sobre l'atribut edat, ha influït de manera significativa en la distribució de les dades. Tal com es pot veure en els gràfics.

<H3>4.3. Aplicació de proves estadístiques per comparar els grups de dades. En funció de les dades i de l’objectiu de l’estudi, aplicar proves de contrast d’hipòtesis,
correlacions, regressions, etc. Aplicar almenys tres mètodes d’anàlisi diferents. </H3>

Es crea un model per a predir si una persona sobreviurà o no
```{r}
train<-data[1:891,]
test<-data[892:1309,]

#install.packages("C50",dependencies=TRUE)
library(C50)
vars<-c("Pclass","Sex","Age","SibSp","Parch","Fare")
str(data[c(vars,"Survived")])
train$Survived<-as.factor(train$Survived)
tree_mod <-C5.0(x=train[,vars],y=train$Survived)
summary(tree_mod)
p1<-predict(tree_mod,test)
summary(p1)
table(test$Survived,Predicted=p1)
plot(tree_mod)
plot(tree_mod,type="simple")
```


Ara utilitzarem mètodes de regressió múltiple per esbrinar quins són els atributs que tenen un pes més significatiu en la supervivencia d'una persona.


```{r}
#train<-data[1:891,]
#test<-data[892:1309,]
modelA<-lm(data$Survived ~ data$Sex + data$Age)
modelB<-lm(data$Survived ~ data$Sex + data$Age + data$Pclass)
modelC<-lm(data$Survived ~ data$Sex + data$Age + data$Pclass + data$SibSp)
modelD<-lm(data$Survived ~ data$Sex + data$Age + data$Pclass + data$SibSp + data$Embarked)
modelE<-lm(data$Survived ~ data$Sex + data$Age + data$Pclass + data$SibSp + data$Embarked + data$Fare)
modelF<-lm(data$Survived ~ data$Sex + data$Age + data$Pclass + data$SibSp + data$Embarked + data$Fare + data$Parch)

taulaReg<-matrix(c('A',summary(modelA)$r.squared,
                    'B',summary(modelB)$r.squared,
                    'C',summary(modelC)$r.squared,
                    'D',summary(modelD)$r.squared,
                    'E',summary(modelE)$r.squared,
                    'F',summary(modelF)$r.squared), ncol=2, byrow = TRUE)

colnames(taulaReg)<-c("Model","R^2")
taulaReg

```

Els resultats obtinguts no són especialment bons, el millor dels models el F, només explica el 52% dels casos totals, pero la diferencia del model f amb el C és infima, donat que els nous atributs introduits no són significatius. De totes maneres ens es útil per veure com influeixen els atributs en la supervivencia.

```{r}
summary(modelF)

```

Podem veure com els atributs més significatius són el sex, age, Pclass i SibSp. El mòdel ens indica que si el sexe = home les probabilitats de supervivencia cauen de manera significativa, al igual que si esten en segona classe o especialment en la tercera.

En canvi els atributs Embarked, Fare i Parch són poc significatius a l'hora d'explicar la supervivencia.

```{r}
pred<-predict(modelF)

table(data$Survived,pred>0.5)

```

Depenent del umbral de tall obtindrem més falsos positius o falsos negatius, de totes maneres amb el model obtingut, el nivell d'errors él bastant alt.



Afegeixo un model de predicció, basat en NaiveBayes. Elimino les columnes que no tindrien impacte en la predicció.Eliminant les columnes Parch, Ticket, Fare i embarked, s'obté un model molt acurat.

```{r include=FALSE}
library(e1071)
library(caret)
```



```{r}

dataNaiveBayes <- data

dataNaiveBayes <- within(dataNaiveBayes,{
      Parch <- NULL
      Ticket <- NULL
      Fare <- NULL
      Embarked <- NULL
  })
trainNaiveBayes<-dataNaiveBayes[1:891,]
testNaiveBayes<-dataNaiveBayes[892:1309,]
model <- naiveBayes(Survived ~ ., data = trainNaiveBayes)
model
pred <- predict(model,testNaiveBayes)
tab <- table(testNaiveBayes$Survived, pred, dnn=c("Actual", "Predita"))
confusionMatrix(tab)
```
