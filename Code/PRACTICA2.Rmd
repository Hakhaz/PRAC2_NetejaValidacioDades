---
title: 'Pràctica 2: Neteja i validació de les dades'
author: "Carlos Pérez Martín i Oscar Fernandez Castro"
date: "18 de mayo de 2019"
output:
  html_document: default
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
data_train<- read.csv('D:/Google Drive/Master Data Science/2018-19_2/Tipologia i cicle de vida de les dades/PRAC2. Neteja i validació de dades/titanic/train.csv',header=T,sep=",", encoding = "UTF-8")
str(data_train)
```

<H3>1. Descripció del dataset. Perquè és important i quina pregunta/problema pretén respondre?</H3>

Els datasets obtingut de https://www.kaggle.com, contenen informació sobre els passatgers del titanic. Des de dades demogràfiques dels passatgers fins a si van sobreviure o no al viatge.

En total hi han 3 datatsets:

- train: 12 atributs amb 891 files.
- test: 11 atributs amb 418 files.
- gender_submission: 2 atributs amb 418 files.

Els tres datasets formen un conjunt de prova i d'entrenament.

Els atributs que tenim en els diferents datasets són:

- Survival: Supervivent (0 = No, 1 = Si)
- Pclass: Classe del passatger (1= 1era, 2 = 2ona, 3 = 3ra)
- Name: Nom
- Sex: Sexe (female, male)
- Age: edad
- Sibsp: Nombre de familiars
- Parch: Nombre de pares/fills embarcats
- Ticket: Número d'entrada
- Fare: Tarifa
- Cabin: cabina
- Embarked: Embarcat (C = Cherbourg, Q = Queenstown, S = Southampton)

La pregunta que volem respondre, és quins són els factors més determinants que influeixen en la taxa de supervivència del passatge. Quins atributs tenen un impacte més elevat? (sexe, classe, edat, etc). Per això s'utilitzaran mètodes de regressió per avaluar les relacions entre atributs.

A continuació es mostra un resum de les dades a analitzar.
```{r}
summary(data_train)
```

<H3>2. Integració i selecció de les dades d’interès a analitzar.</H3>

Per començar unificarem els tres datasets en un per fer la neteja de les dades. Després en cas necessari ja se separaran de nou en conjunts de prova i d'entrenament.

```{r}
data_test<- read.csv('D:/Google Drive/Master Data Science/2018-19_2/Tipologia i cicle de vida de les dades/PRAC2. Neteja i validació de dades/titanic/test.csv',header=T,sep=",", encoding = "UTF-8")
data_sub<-read.csv('D:/Google Drive/Master Data Science/2018-19_2/Tipologia i cicle de vida de les dades/PRAC2. Neteja i validació de dades/titanic/gender_submission.csv',header=T,sep=",", encoding = "UTF-8")

#unifiquem el dataset de test amb els seus resultats
data_test <- merge(data_test,data_sub, by="PassengerId")

#juntem les files dels datasets de train i test
data<-rbind(data_train, data_test)
```

Ara ja tenim el dataset complet amb 1309 registres i 12 atributs.

Volem analitzar el nombre més gran d'atributs possibles, però a simple vista, ja podem dir que els atributs Name i PassangerId, no ens aporten informació, així que els eliminarem.

Agafarem l'atribut survived com a referència i utilitzant diferents mètodes estadístics, veurem quin impacte tenen els altres atributs sobre aquest.


<H3>3. Neteja de les dades.</H3>

Al fer una revisió del tipus de dades, veiem que l'atribut Pclass és de tipus enter, quan hauria de ser de tipus factor.
En el cas de l'atribut Survived també és de tipus enter quan hauria de ser binari. L'atribut survived es podría convertir a un atribut de tipus lògic (true/false)

Tipus de dades abans de la conversió
```{r}
sapply(data,class)
```
Tipus de dades desprès de la conversió
```{r}
data$Pclass<-as.factor(data$Pclass)
data$Survived<-as.logical(data$Survived)
sapply(data,class)
```


<H3>3.1. Les dades contenen zeros o elements buits? Com gestionaries aquests casos?</H3>

Busquem en tots els atributs els valors NA i buits.
          
Valors NA
```{r}
sapply(data, function(x) sum(is.na(x)))
```

Valors buits
```{r}
sapply(data, function(x) sum(x==""))
```

L'atribut Age té 263 casos amb valor NA, i l'atribut Embarked 2 casos de valor buit. En cada cas utilitzarem una tècnica diferent, per l'atribut age, substituirem els valors NA segons k-Nearest Neighbors (kNN), i en el cas de l'atribut embarked els modificarem per l'atribut majoritari.

```{r include=FALSE}
library(VIM)
```

```{r}
data$Age <- kNN(data)$Age
data$Embarked[data$Embarked==""]<- "S"
#data$Age[is.na(data$Age)]<-28 #mediana = 28
```
Un cop modificat el valor d'Age, volem veure si aquesta modificació ha tingut un gran impacte. Creem un dataframe nou, amb les dades sense modificar, y es comparen les dades modificades amb la mitjana amb les dades originals.

```{r}
data2<-rbind(data_train, data_test)
par(mfrow=c(1,2))
hist(data$Age, freq=F, main="Age: values NA with mean",col='darkgreen', ylim=c(0,0.04))
hist(data2$Age, freq=F, main="Age: Original Data",col='lightgreen', ylim=c(0,0.04))
```
Es pot observar que el fet de modificar els valors NA d'Age seguint el mètode de k-Nearest Neighbors no afecta gaire a la distribució dels valors, per tant es pot concluir que es una bona aproximació dels valors.

En el cas de l'atribut cabina (cabin) tenim 1014 registres buits dels 1309 del dataset. A més els valors que tenim estan molt fragmentats. En aquestes circumstancies l'atibut cabina no ens aportarà informació rellevant o fiable, així que l'eliminarem en la part de selecció d'atributs (apartat 4.1).

L'atribut tarifa (fare) conté un valor NA. En aquest cas el modifiquem i li posem la mitjana. Per a no pasarli un valor fixe, modifiquem la forma de assignar la mitjana al valor nul. Calculo la mitjana de la variable Fare, excloent al càlcul els valors NA.

```{r}
data$Fare[is.na(data$Fare)] <- mean(data$Fare, na.rm=TRUE)
```



<H3>3.2. Identificació i tractament de valors extrems.</H3>

Busquem valors extrems en els atributs númerics. Comencem amb un mètode molt visualt, el blotpox.

```{r}

par(mfrow=c(2,2))
for(i in 2:ncol(data)) #ignorem PassengerId
{
  if ((is.numeric(data[,i]))||(is.integer(data[,i])))
  {
    boxplot(data[,i], main = colnames(data)[i], width=100) 
  }
  
}

```


```{r}
boxplot.stats(data$Age)$out
boxplot.stats(data$SibSp)$out
boxplot.stats(data$Parch)$out
boxplot.stats(data$Fare)$out
```

Els valors dels outliers mostrar pel boxplot de l'atribut edat són valors coherents, no els considerem outliers, ja que es mostren forà del gràfic per la concentració de valors entre els 20 i 30 anys.

El mateix es pot dir pels atributs SibSp i Parch, la majoria de regsitres tenen valor 0, i fa que el boxplot estigui molt comprimit en aquest interval. Tenir 8 fills és un valor elevat, pero no es pot considerar irreal.

En el cas de l’atribut Fare revisarem a continuació amb més detall els seus valors depenent de l’atribut Pclass, que clarament està relacionat.

```{r}
par(mfrow=c(2,2))
boxplot(data$Fare[data$Pclass==1], main = "Fare - Pclass=1", width=100) 
boxplot(data$Fare[data$Pclass==2], main = "Fare - Pclass=2", width=100) 
boxplot(data$Fare[data$Pclass==3], main = "Fare - Pclass=3", width=100) 

summary(data$Fare[data$Pclass==1])
summary(data$Fare[data$Pclass==2])
summary(data$Fare[data$Pclass==3])
```
Un cop analitzat la tarifa dels bitllets de les diferents classes, observant els valors mitjans, es pot observar una diferència raonable en els preus dels bitllets entre les diferents classes, sent més alta la tarifa a primera classe i més baixa a tercera. Tot i això, sobretot a tercera classe, s'observen uns preus extrems, que podríem considerar erronis, però degut a que no disposem de més informació, decidirem no tractar amb aquests valors, degut a que podría ser correcta aquesta informació.

<H3>4. Anàlisi de les dades.</H3>
<H3>4.1. Selecció dels grups de dades que es volen analitzar/comparar (planificació dels anàlisis a aplicar).</H3>

Com ja hem comentat anteriorment, tenim atributs que no aporten cap informació útil (PassengerId, Name), i d'altres que tenen masses registres buits perquè puguin aportar informació valida (Cabin). Els eliminem.

```{r}
data<-data[ , -which(names(data) %in% c("PassengerId","Name","Cabin"))]
```

Es vol comparar quins pesos tenen els diferents atributs sobre la supervivenvia o no d'un individu, quins són els factors que més influeixen.

<H3>4.2. Comprovació de la normalitat i homogeneïtat de la variància.</H3>

Per comprobar la normailitat de les dades fem servir un anàlisi visual (qqplot i histograma) i el test shapiro-wilk.

```{r}

par(mfrow=c(2,2))
for(i in 1:ncol(data))
{
  if ((is.numeric(data[,i]))|(is.integer(data[,i])))
  {
    qqnorm(data[,i], main = colnames(data)[i]);qqline(data[,i])
    hist(data[,i], main = colnames(data)[i])
  }
}

```

Apliquem l'algoritme de shapiro-wilk.

```{r}
shapiro.test(data$Age)
shapiro.test(data$SibSp)
shapiro.test(data$Parch)
shapiro.test(data$Fare)
```

Els tests de shapiro-wilk ens retornen un p-valor inferior a 0.05 per tant no es compleix la hipòtesis nul·la i per tant les dades no segueixen una distribució normal.

Tant els gràfics com el test de shapiro-wilk, ens indiquen que les dades no segueixen una distribució normal. Però sabem pel que diu el teorema del límit central, que si tenim més de 30 distribucions, es pot aproximar a una distribució normal de mitja 0 i desviació estàndard 1.

La neteja de dades realitzada sobre l'atribut edat, ha influït de manera significativa en la distribució de les dades. Tal com es pot veure en els gràfics.

```{r setup2, include=FALSE}
write.csv(data,'D:/Google Drive/Master Data Science/2018-19_2/Tipologia i cicle de vida de les dades/PRAC2. Neteja i validació de dades/titanic/dataOut.csv',row.names=FALSE)
```

<H3>4.3. Aplicació de proves estadístiques per comparar els grups de dades. En funció de les dades i de l’objectiu de l’estudi, aplicar proves de contrast d’hipòtesis,
correlacions, regressions, etc. Aplicar almenys tres mètodes d’anàlisi diferents. </H3>

<H4>Model d'arbre de classificació</H4>
El primer model creat, per a predir si un passatger sobreviu o no, serà un model d'arbre de classificació. El primer pas es generar el conjunt d'entrenament, amb el qual es crearà el model, i el conjunt de test, amb el qual es comprobarà com de bo es el model.

```{r}
train<-data[1:891,]
test<-data[892:1309,]

library(C50)
vars<-c("Pclass","Sex","Age","SibSp","Parch","Fare")
str(data[c(vars,"Survived")])
train$Survived<-as.factor(train$Survived)
tree_mod <-C5.0(x=train[,vars],y=train$Survived)
```

A continuació es mostra el model d'arbre de classificació generat.
```{r}
summary(tree_mod)
plot(tree_mod)
plot(tree_mod,type="simple")
```

Un cop generat el model, es vol comprobar que el model funciona correctament. Per això, utilitzem el conjunt de test per a comprobar com de bo es el model.
```{r}
p1<-predict(tree_mod,test)
summary(p1)
table(test$Survived,Predicted=p1)
```
Com es pot observar, mitjançant aquest model, dels  passatgers que no van sobreviure, classifica 254 casos com a que no sobreviuen, y 12 que sí, mentre que dels que sí van sobreviure, classifica 146 com a que sobreviuen y nomès 12 que no. Per tant, el model de classificació generat es bastant acurat i permet predir de forma bastant exacta si un passatger va sobreviure o no.

<H4>Model de regressió múltiple</H4>
Ara utilitzarem mètodes de regressió múltiple per esbrinar quins són els atributs que tenen un pes més significatiu en la supervivencia d'una persona.


```{r}
#train<-data[1:891,]
#test<-data[892:1309,]
modelA<-lm(data$Survived ~ data$Sex + data$Age)
modelB<-lm(data$Survived ~ data$Sex + data$Age + data$Pclass)
modelC<-lm(data$Survived ~ data$Sex + data$Age + data$Pclass + data$SibSp)
modelD<-lm(data$Survived ~ data$Sex + data$Age + data$Pclass + data$SibSp + data$Embarked)
modelE<-lm(data$Survived ~ data$Sex + data$Age + data$Pclass + data$SibSp + data$Embarked + data$Fare)
modelF<-lm(data$Survived ~ data$Sex + data$Age + data$Pclass + data$SibSp + data$Embarked + data$Fare + data$Parch)

taulaReg<-matrix(c('A',summary(modelA)$r.squared,
                    'B',summary(modelB)$r.squared,
                    'C',summary(modelC)$r.squared,
                    'D',summary(modelD)$r.squared,
                    'E',summary(modelE)$r.squared,
                    'F',summary(modelF)$r.squared), ncol=2, byrow = TRUE)

colnames(taulaReg)<-c("Model","R^2")
taulaReg

```

Els resultats obtinguts no són especialment bons, el millor dels models el F, només explica el 52% dels casos totals, pero la diferencia del model f amb el C és infima, donat que els nous atributs introduits no són significatius. De totes maneres ens es útil per veure com influeixen els atributs en la supervivencia.

```{r}
summary(modelF)

```

Podem veure com els atributs més significatius són el sex, age, Pclass i SibSp. El mòdel ens indica que si el sexe = home les probabilitats de supervivencia cauen de manera significativa, al igual que si esten en segona classe o especialment en la tercera.

En canvi els atributs Embarked, Fare i Parch són poc significatius a l'hora d'explicar la supervivencia.

```{r}
pred<-predict(modelF)

table(data$Survived,pred>0.5)

```

Depenent del umbral de tall obtindrem més falsos positius o falsos negatius, de totes maneres amb el model obtingut, el nivell d'errors él bastant alt.

<H4>Model de classificació Bayesià</H4>

Per últim es decideix generar un segon model de classificació, però aquest cop seguint un classificador Bayesià ingenu, mitjançant NaiveBayes. NaiveBayes es un algoritme d'aprenentatge automàtic basat en el teorema de Bayes.

El primer pas es establir quines variables s'utilitzaràn per a generar el model. Desprès de diverses probes, s'ha vist que, el·liminant les variables Parch, Ticket, Fare y Embarked, s'aconsegueix el model més exacte. Per tant, el primer punt es el·liminar aquestes variables. Això permet assegurar que els resultats del model de regressió múltiple anterior son correctes, ja que amb les variables més rellevants que s'indiquen al model anterior, es quan s'aconsegueix el millor model de predicció.

```{r include=FALSE}
library(e1071)
library(caret)
```

```{r}
dataNaiveBayes <- data

dataNaiveBayes <- within(dataNaiveBayes,{
      Parch <- NULL
      Ticket <- NULL
      Fare <- NULL
      Embarked <- NULL
  })
trainNaiveBayes<-dataNaiveBayes[1:891,]
testNaiveBayes<-dataNaiveBayes[892:1309,]
```

El model generat es el següent.
```{r}
model <- naiveBayes(Survived ~ ., data = trainNaiveBayes)
model
```

Un cop generat el model, es proba el model amb el conjunt de test.
```{r}
pred <- predict(model,testNaiveBayes)
tab <- table(testNaiveBayes$Survived, pred, dnn=c("Actual", "Predita"))
confusionMatrix(tab)
```

Un cop probat el model amb el conjunt de test, es pot observar que aquest es més acurat que el model d'arbre de classificació anterior a l'hora de predir si un passatger sobreviu o no.

Finalment es mostren les 4 variables utilitzades, comparant els resultats de les dades originals i les dades predites pel model, per comprobar visualment la qualitat del model.

```{r}
testNaiveBayes$Prediccion <- pred
par(mfrow=c(2,2))
barplot(table(testNaiveBayes$Survived[testNaiveBayes$Sex == "male"]), main="Original survived male",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$Sex == "male"]), main="Predicted survived male",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Survived[testNaiveBayes$Sex == "female"]), main="Original survived female",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$Sex == "female"]), main="Predicted survived female",xlab="Survived",ylab="count")
```
```{r}
par(mfrow=c(3,2))
barplot(table(testNaiveBayes$Survived[testNaiveBayes$Pclass == "1"]), main="Original survived class 1",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$Pclass == "1"]), main="Predicted survived class 1",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Survived[testNaiveBayes$Pclass == "2"]), main="Original survived class 2",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$Pclass == "2"]), main="Predicted survived class 2",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Survived[testNaiveBayes$Pclass == "3"]), main="Original survived class 3",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$Pclass == "3"]), main="Predicted survived class 3",xlab="Survived",ylab="count")
```

```{r}
par(mfrow=c(2,2))
barplot(table(testNaiveBayes$Survived[testNaiveBayes$SibSp == "0"]), main="Original survived family members 0",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$SibSp == "0"]), main="Predicted survived family members 0",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Survived[testNaiveBayes$SibSp == "1"]), main="Original survived family members 1",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$SibSp == "1"]), main="Predicted survived family members 1",xlab="Survived",ylab="count")
```
```{r}
par(mfrow=c(2,2))
barplot(table(testNaiveBayes$Survived[testNaiveBayes$SibSp == "2"]), main="Original survived family members 2",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$SibSp == "2"]), main="Predicted survived family members 2",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Survived[testNaiveBayes$SibSp == "3"]), main="Original survived family members 3",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$SibSp == "3"]), main="Predicted survived family members 3",xlab="Survived",ylab="count")
```
```{r}
par(mfrow=c(2,2))
barplot(table(testNaiveBayes$Survived[testNaiveBayes$SibSp == "4"]), main="Original survived family members 4",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$SibSp == "4"]), main="Predicted survived family members 4",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Survived[testNaiveBayes$SibSp == "5"]), main="Original survived family members 5",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$SibSp == "5"]), main="Predicted survived family members 5",xlab="Survived",ylab="count")
```

```{r}
par(mfrow=c(1,2))
barplot(table(testNaiveBayes$Survived[testNaiveBayes$SibSp == "8"]), main="Original survived family members 8",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$SibSp == "8"]), main="Original survived family members 8",xlab="Survived",ylab="count")
```

```{r}
testNaiveBayes$Age[testNaiveBayes$Age<"19"]<- "<=18"
testNaiveBayes$Age[testNaiveBayes$Age>"65"]<- ">65"
testNaiveBayes$Age[(testNaiveBayes$Age>"18")&(testNaiveBayes$Age<"31")]<- ">18 and <=30"
testNaiveBayes$Age[(testNaiveBayes$Age>"30")&(testNaiveBayes$Age<"51")]<- ">30 and <=50"
testNaiveBayes$Age[(testNaiveBayes$Age>"50")&(testNaiveBayes$Age<"66")]<- ">50 and <=65"
```
```{r}
par(mfrow=c(2,2))
barplot(table(testNaiveBayes$Survived[testNaiveBayes$Age == "<=18"]), main="Original survived <=18 years",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$Age == "<=18"]), main="Predicted survived <= 18 years",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Survived[testNaiveBayes$Age == ">18 and <=30"]), main="Original survived >18 and <= 30 years",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$Age == ">18 and <=30"]), main="Predicted survived >18 and <= 30 years",xlab="Survived",ylab="count")
```
```{r}
par(mfrow=c(2,2))
barplot(table(testNaiveBayes$Survived[testNaiveBayes$Age == ">30 and <=50"]), main="Original survived >30 and <= 50 years",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$Age == ">30 and <=50"]), main="Predicted survived >30 and <= 50 years",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Survived[testNaiveBayes$Age == ">50 and <=65"]), main="Original survived >50 and <= 65 years",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$Age == ">50 and <=65"]), main="Predicted survived >50 and <= 65 years",xlab="Survived",ylab="count")
```
```{r}
par(mfrow=c(2,2))
barplot(table(testNaiveBayes$Survived[testNaiveBayes$Age == ">65"]), main="Original survived >65 years",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$Age == ">65"]), main="Predicted survived >65 years",xlab="Survived",ylab="count")
```


<H3>5. Representació dels resultats a partir de taules i gràfiques.</H3>
Durant la resolució dels diferents apartats es van generant les taules i gràfiques necessàries per a la presentació dels resultats obtinguts.

<H3>6. Resolució del problema.A partir dels resultats obtinguts, quines són les conclusions? Els resultats permeten respondre al problema?</H3>

Un cop realitzat tot l'anàlisi, es pot assegurar que les variables necessàries per a predir si un passatger sobreviu o no són: Sex, Age, Pclass i SibSp
 
Generant un model amb aquestes dades som capaços de predir, amb una exactitud del 96,65%, si un passatger sobreviu o no, utilitzant únicament les dades esmentades.

Per tant, com a conclusió, podem dir que s'ha aconseguit respondre a les preguntes inicials, que era estudiar quines variables tenen més impacte en la taxa de supervivència dels passatgers i, mitjançant aquestes, generar un model adequat per a predir qualsevol altre cas possible.

<H3>7. Codi</H3>
Es pot trobar el codi a la carpeta Code del github (https://github.com/Hakhaz/NetejaValidacioDades)


<table class="egt">

  <tr>

    CONTRIBUCIONS                 SIGNATURA
    Investigació prèvia           CPM, OFC
    Redacció de les respostes     CPM, OFC
    Desenvolupament codi          CPM, OFC

  </tr>

</table>
