---
title: 'Pràctica 2: Neteja i validació de les dades'
author: "Carlos Pérez Martín i Oscar Fernandez Castro"
date: "18 de mayo de 2019"
output:
  pdf_document: default
  html_document: default
  word_document: default
---

```{r setup, include=FALSE}
data_train<- read.csv('C:/Users/vodsk/Desktop/UOC/Topologia i cicle de vida de les dades/PRACTICA2/kaggle-titanic-master/input/train.csv',header=T,sep=",", encoding = "UTF-8")
str(data_train)
```

<H3>1. Descripció del dataset. Perquè és important i quina pregunta/problema pretén respondre?</H3>

Els datasets obtingut de https://www.kaggle.com, contenen informació sobre els passatgers del titanic. Des de dades demogràfiques dels passatgers fins a si van sobreviure o no al viatge.

En total hi han 3 datatsets:

- train: 12 atributs amb 891 files.
- test: 11 atributs amb 418 files.
- gender_submission: 2 atributs amb 418 files.

Els tres datasets formen un conjunt de prova i d'entrenament.

Els atributs que tenim en els diferents datasets són:

- Survival: Supervivent (0 = No, 1 = Si)
- Pclass: Classe del passatger (1= 1era, 2 = 2ona, 3 = 3ra)
- Name: Nom
- Sex: Sexe (female, male)
- Age: edad
- Sibsp: Nombre de familiars
- Parch: Nombre de pares/fills embarcats
- Ticket: Número d'entrada
- Fare: Tarifa
- Cabin: cabina
- Embarked: Embarcat (C = Cherbourg, Q = Queenstown, S = Southampton)

La pregunta que volem respondre, és quins són els factors més determinants que influeixen en la taxa de supervivència del passatge. Quins atributs tenen un impacte més elevat? (sexe, classe, edat, etc). Per això s'utilitzaran mètodes de regressió per avaluar les relacions entre atributs.

A continuació es mostra un resum de les dades a analitzar.
```{r}
summary(data_train)
```

<H3>2. Integració i selecció de les dades d’interès a analitzar.</H3>

Per començar unificarem els tres datasets en un per fer la neteja de les dades. Després en cas necessari ja se separaran de nou en conjunts de prova i d'entrenament.

```{r}
data_test<- read.csv('C:/Users/vodsk/Desktop/UOC/Topologia i cicle de vida de les dades/PRACTICA2/kaggle-titanic-master/input/test.csv',header=T,sep=",", encoding = "UTF-8")
data_sub<-read.csv('C:/Users/vodsk/Desktop/UOC/Topologia i cicle de vida de les dades/PRACTICA2/kaggle-titanic-master/input/gender_submission.csv',header=T,sep=",", encoding = "UTF-8")
#unifiquem el dataset de test amb els seus resultats
data_test <- merge(data_test,data_sub, by="PassengerId")
#juntem les files dels datasets de train i test
data<-rbind(data_train, data_test)
```

Ara ja tenim el dataset complet amb 1309 registres i 12 atributs.

Volem analitzar el nombre més gran d'atributs possibles, però a simple vista, ja podem dir que els atributs Name i PassangerId, no ens aporten informació, així que els eliminarem.

Agafarem l'atribut survived com a referència i utilitzant diferents mètodes estadístics, veurem quin impacte tenen els altres atributs sobre aquest.


<H3>3. Neteja de les dades.</H3>

Al fer una revisió del tipus de dades, veiem que l'atribut Pclass és de tipus enter, quan hauria de ser de tipus factor.
En el cas de l'atribut Survived també és de tipus enter quan hauria de ser binari. L'atribut survived es podría convertir a un atribut de tipus lògic (true/false)

Tipus de dades abans de la conversió
```{r}
sapply(data,class)
```
Tipus de dades desprès de la conversió
```{r}
data$Pclass<-as.factor(data$Pclass)
data$Survived<-as.logical(data$Survived)
sapply(data,class)
```


<H3>3.1. Les dades contenen zeros o elements buits? Com gestionaries aquests casos?</H3>

Busquem en tots els atributs els valors NA i buits.
          
Valors NA
```{r}
sapply(data, function(x) sum(is.na(x)))
```

Valors buits
```{r}
sapply(data, function(x) sum(x==""))
```

L'atribut Age té 263 casos amb valor NA, i l'atribut Embarked 2 casos de valor buit. En cada cas utilitzarem una tècnica diferent, per l'atribut age, substituirem els valors NA segons k-Nearest Neighbors (kNN), i en el cas de l'atribut embarked els modificarem per l'atribut majoritari.

```{r include=FALSE}
library(VIM)
```

```{r}
data$Age <- kNN(data)$Age
data$Embarked[data$Embarked==""]<- "S"
#data$Age[is.na(data$Age)]<-28 #mediana = 28
```
Un cop modificat el valor d'Age, volem veure si aquesta modificació ha tingut un gran impacte. Creem un dataframe nou, amb les dades sense modificar, y es comparen les dades modificades amb la mitjana amb les dades originals.

```{r}
data2<-rbind(data_train, data_test)
par(mfrow=c(1,2))
hist(data$Age, freq=F, main="Age: values NA with mean",col='darkgreen', ylim=c(0,0.04))
hist(data2$Age, freq=F, main="Age: Original Data",col='lightgreen', ylim=c(0,0.04))
```
Es pot observar que el fet de modificar els valors NA d'Age seguint el mètode de k-Nearest Neighbors no afecta gaire a la distribució dels valors, per tant es pot concluir que es una bona aproximació dels valors.

En el cas de l'atribut cabina (cabin) tenim 1014 registres buits dels 1309 del dataset. A més els valors que tenim estan molt fragmentats. En aquestes circumstancies l'atibut cabina no ens aportarà informació rellevant o fiable, així que l'eliminarem en la part de selecció d'atributs (apartat 4.1).

L'atribut tarifa (fare) conté un valor NA. En aquest cas el modifiquem i li posem la mitjana. Per a no pasarli un valor fixe, modifiquem la forma de assignar la mitjana al valor nul. Calculo la mitjana de la variable Fare, excloent al càlcul els valors NA.

```{r}
data$Fare[is.na(data$Fare)] <- mean(data$Fare, na.rm=TRUE)
```



<H3>3.2. Identificació i tractament de valors extrems.</H3>

Busquem valors extrems en els atributs númerics. Comencem amb un mètode molt visualt, el blotpox.

```{r}
par(mfrow=c(2,2))
for(i in 2:ncol(data)) #ignorem PassengerId
{
  if ((is.numeric(data[,i]))||(is.integer(data[,i])))
  {
    boxplot(data[,i], main = colnames(data)[i], width=100) 
  }
  
}
```


```{r}
boxplot.stats(data$Age)$out
boxplot.stats(data$SibSp)$out
boxplot.stats(data$Parch)$out
boxplot.stats(data$Fare)$out
```

Els valors dels outliers mostrar pel boxplot de l'atribut edat són valors coherents, no els considerem outliers, ja que es mostren forà del gràfic per la concentració de valors entre els 20 i 30 anys.

El mateix es pot dir pels atributs SibSp i Parch, la majoria de regsitres tenen valor 0, i fa que el boxplot estigui molt comprimit en aquest interval. Tenir 8 fills és un valor elevat, pero no es pot considerar irreal. Per tant, observant els valors de les variables, no es troba necessari realitzar cap altre anàlisi de valors extrems ja que, pels valors que es donen, no es pot considerar cap un valor extrem.

En el cas de l’atribut Fare revisarem a continuació amb més detall els seus valors depenent de l’atribut Pclass, que clarament està relacionat.

```{r}
par(mfrow=c(2,2))
boxplot(data$Fare[data$Pclass==1], main = "Fare - Pclass=1", width=100) 
boxplot(data$Fare[data$Pclass==2], main = "Fare - Pclass=2", width=100) 
boxplot(data$Fare[data$Pclass==3], main = "Fare - Pclass=3", width=100) 
summary(data$Fare[data$Pclass==1])
summary(data$Fare[data$Pclass==2])
summary(data$Fare[data$Pclass==3])
```

<br>
Un cop analitzat la tarifa dels bitllets de les diferents classes, observant els valors mitjans, es pot observar una diferència raonable en els preus dels bitllets entre les diferents classes, sent més alta la tarifa a primera classe i més baixa a tercera. Tot i això, sobretot a tercera classe, s'observen uns preus extrems, que podríem considerar erronis, però degut a que no disposem de més informació, decidirem no tractar amb aquests valors, degut a que podría ser correcta aquesta informació.

<H3>4. Anàlisi de les dades.</H3>
<H3>4.1. Selecció dels grups de dades que es volen analitzar/comparar (planificació dels anàlisis a aplicar).</H3>

Com ja hem comentat anteriorment, tenim atributs que no aporten cap informació útil (PassengerId, Name), i d'altres que tenen masses registres buits perquè puguin aportar informació valida (Cabin). Els eliminem.

```{r}
data<-data[ , -which(names(data) %in% c("PassengerId","Name","Cabin"))]
```

Es vol comparar quins pesos tenen els diferents atributs sobre la supervivenvia o no d'un individu, quins són els factors que més influeixen.

<H3>4.2. Comprovació de la normalitat i homogeneïtat de la variància.</H3>

Per comprobar la normalitat de les dades fem servir un anàlisi visual (qqplot i histograma) i el test shapiro-wilk.

```{r}
par(mfrow=c(2,2))
for(i in 1:ncol(data))
{
  if ((is.numeric(data[,i]))|(is.integer(data[,i])))
  {
    qqnorm(data[,i], main = colnames(data)[i]);qqline(data[,i])
    hist(data[,i], main = colnames(data)[i])
  }
}
```

Amb una primera ullada, es veu clarament que els atributs SibSp, Parch i Fare no tenen una distribució normal.

Apliquem l'algoritme de shapiro-wilk per l'atribut edat i la prova no paramètrica de wilcox per els atributs Sibsp, Parch i Fare.

```{r}
shapiro.test(data$Age)
wilcox.test(data$SibSp)
wilcox.test(data$Parch)
wilcox.test(data$Fare)
```


Els test de shapiro-wilk i el de wilcox ens retornen un p-valor inferior a 0.05 per tant no es compleix la hipòtesi nul·la i per tant les dades no segueixen una distribució normal.

Tant els gràfics com el test de shapiro-wilk, ens indiquen que les dades no segueixen una distribució normal. Però sabem pel que diu el teorema del límit central, que si tenim més de 30 distribucions, es pot aproximar a una distribució normal de mitja 0 i desviació estàndard 1.

Ara revisem l'homogeneïtat de la variància. Com no es compleix la condició de normalitat d'algunes mostres, utilitzem la prova de  Fligner-Killen. En aquesta prova la hipòtesis nul·la diu que les variàncies són iguals i que els diferents valors no afecten.

Compararem els atributs en qüestió respecte a l'objectiu de la pràctica que és mesurar la influencia sobre l'atribut survived.

```{r}
fligner.test(data$Survived ~ data$Age, data=data)
fligner.test(data$Survived ~ data$SibSp, data=data)
fligner.test(data$Survived ~ data$Parch, data=data)
fligner.test(data$Survived ~ data$Fare, data=data)
```

Els resultats ens mostren que la variància de la superviencia és similar pels atributs age i fare, pero que varia pels diferents valors de SibSp i Parch.


```{r setup2, include=FALSE}
write.csv(data,'C:/Users/vodsk/Desktop/UOC/Topologia i cicle de vida de les dades/PRACTICA2/kaggle-titanic-master/input/dataOut.csv',row.names=FALSE)
```

<H3>4.3. Aplicació de proves estadístiques per comparar els grups de dades. En funció de les dades i de l’objectiu de l’estudi, aplicar proves de contrast d’hipòtesis,
correlacions, regressions, etc. Aplicar almenys tres mètodes d’anàlisi diferents. </H3>

<H4>Model d'arbre de classificació</H4>
El primer model creat, per a predir si un passatger sobreviu o no, serà un model d'arbre de classificació. El primer pas es generar el conjunt d'entrenament, amb el qual es crearà el model, i el conjunt de test, amb el qual es comprobarà com de bo es el model.

```{r}
train<-data[1:891,]
test<-data[892:1309,]
library(C50)
vars<-c("Pclass","Sex","Age","SibSp","Parch","Fare")
str(data[c(vars,"Survived")])
train$Survived<-as.factor(train$Survived)
tree_mod <-C5.0(x=train[,vars],y=train$Survived)
```

A continuació es mostra el model d'arbre de classificació generat.
```{r}
summary(tree_mod)
plot(tree_mod)
plot(tree_mod,type="simple")
```

Un cop generat el model, es vol comprobar que el model funciona correctament. Per això, utilitzem el conjunt de test per a comprobar com de bo es el model.
```{r}
p1<-predict(tree_mod,test)
summary(p1)
table(test$Survived,Predicted=p1)
```
Com es pot observar, mitjançant aquest model, dels  passatgers que no van sobreviure, classifica 254 casos com a que no sobreviuen, y 12 que sí, mentre que dels que sí van sobreviure, classifica 146 com a que sobreviuen y nomès 12 que no. Per tant, el model de classificació generat es bastant acurat i permet predir de forma bastant exacta si un passatger va sobreviure o no.

<H4>Contrast d'hipòtesis</H4>

Apliquem el contrast d'hipòtesi als principals atributs per veure quin d'ells és significatiu respecte l'atribut survived.

H0 : µ1 − µ2 = 0<br>
H1 : µ1 − µ2 > 0

Com a hipòtesi nul·la tenim que el nivell de supervivència de les dades del primer paràmetre és el mateix que les dades del segon paràmetre. Com a hipòtesi alternativa, tenim que les dades del primer fan augmentar el nivell de supervivènvia respecte al segon.

Aplicarem la mateixa hipòtesi als diferents atributs. (amb l'interval de confiança per defecte 0.95)

```{r}
#wilcex necesita el 1er param númeric
data$Survived_num <-as.numeric(data$Survived)

wilcox.test(data$Survived_num[data$Sex == "female"], data$Survived_num[data$Sex == "male"], alternative = "greater")
wilcox.test(data$Survived_num[data$Pclass == "1"], data$Survived_num[data$Pclass == "3"], alternative = "greater")
wilcox.test(data$Survived_num, data$SibSp, alternative = "greater")
wilcox.test(data$Survived_num, data$Parch, alternative = "greater")
wilcox.test(data$Survived_num, data$Fare, alternative = "greater")


```

Com els resultats ens mostren, els atributs rellevants que afecten a la supervivencia són Age, Pclass i Fare. Ja que tenim p-valors propers a 0, per tant en aquests casos hem de descartar la hipòtesi nul·la.

<H4>Model de regressió múltiple</H4>
Ara utilitzarem mètodes de regressió múltiple per esbrinar quins són els atributs que tenen un pes més significatiu en la supervivencia d'una persona.


```{r}
#train<-data[1:891,]
#test<-data[892:1309,]
modelA<-lm(data$Survived ~ data$Sex + data$Age)
modelB<-lm(data$Survived ~ data$Sex + data$Age + data$Pclass)
modelC<-lm(data$Survived ~ data$Sex + data$Age + data$Pclass + data$SibSp)
modelD<-lm(data$Survived ~ data$Sex + data$Age + data$Pclass + data$SibSp + data$Embarked)
modelE<-lm(data$Survived ~ data$Sex + data$Age + data$Pclass + data$SibSp + data$Embarked + data$Fare)
modelF<-lm(data$Survived ~ data$Sex + data$Age + data$Pclass + data$SibSp + data$Embarked + data$Fare + data$Parch)
taulaReg<-matrix(c('A',summary(modelA)$r.squared,
                    'B',summary(modelB)$r.squared,
                    'C',summary(modelC)$r.squared,
                    'D',summary(modelD)$r.squared,
                    'E',summary(modelE)$r.squared,
                    'F',summary(modelF)$r.squared), ncol=2, byrow = TRUE)
colnames(taulaReg)<-c("Model","R^2")
taulaReg
```

Els resultats obtinguts no són especialment bons, el millor dels models el F, només explica el 52% dels casos totals, pero la diferencia del model f amb el C és infima, donat que els nous atributs introduits no són significatius. De totes maneres ens es útil per veure com influeixen els atributs en la supervivencia.

```{r}
summary(modelF)
```

Podem veure com els atributs més significatius són el sex, age, Pclass i SibSp. El mòdel ens indica que si el sexe = home les probabilitats de supervivencia cauen de manera significativa, al igual que si esten en segona classe o especialment en la tercera.

En canvi els atributs Embarked, Fare i Parch són poc significatius a l'hora d'explicar la supervivencia.

```{r}
pred<-predict(modelF)
table(data$Survived,pred>0.5)
```

Depenent del umbral de tall obtindrem més falsos positius o falsos negatius, de totes maneres amb el model obtingut, el nivell d'errors él bastant alt.

<H4>Model de classificació Bayesià</H4>

Per últim es decideix generar un segon model de classificació, però aquest cop seguint un classificador Bayesià ingenu, mitjançant NaiveBayes. NaiveBayes es un algoritme d'aprenentatge automàtic basat en el teorema de Bayes.

El primer pas es establir quines variables s'utilitzaràn per a generar el model. Desprès de diverses probes, s'ha vist que, el·liminant les variables Parch, Ticket, Fare y Embarked, s'aconsegueix el model més exacte. Per tant, el primer punt es el·liminar aquestes variables. Això permet assegurar que els resultats del model de regressió múltiple anterior son correctes, ja que amb les variables més rellevants que s'indiquen al model anterior, es quan s'aconsegueix el millor model de predicció.

```{r include=FALSE}
library(e1071)
library(caret)
```

```{r}
dataNaiveBayes <- data
dataNaiveBayes <- within(dataNaiveBayes,{
      Parch <- NULL
      Ticket <- NULL
      Fare <- NULL
      Embarked <- NULL
  })
trainNaiveBayes<-dataNaiveBayes[1:891,]
testNaiveBayes<-dataNaiveBayes[892:1309,]
```

El model generat es el següent.
```{r}
model <- naiveBayes(Survived ~ ., data = trainNaiveBayes)
model
```

Un cop generat el model, es proba el model amb el conjunt de test.
```{r}
pred <- predict(model,testNaiveBayes)
tab <- table(testNaiveBayes$Survived, pred, dnn=c("Actual", "Predita"))
confusionMatrix(tab)
```

Un cop probat el model amb el conjunt de test, es pot observar que aquest es més acurat que el model d'arbre de classificació anterior a l'hora de predir si un passatger sobreviu o no.

Finalment es mostren les 4 variables utilitzades, comparant els resultats de les dades originals i les dades predites pel model, per comprobar visualment la qualitat del model.

```{r}
testNaiveBayes$Prediccion <- pred
par(mfrow=c(2,2))
barplot(table(testNaiveBayes$Survived[testNaiveBayes$Sex == "male"]), main="Original survived male",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$Sex == "male"]), main="Predicted survived male",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Survived[testNaiveBayes$Sex == "female"]), main="Original survived female",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$Sex == "female"]), main="Predicted survived female",xlab="Survived",ylab="count")
```
```{r}
par(mfrow=c(3,2))
barplot(table(testNaiveBayes$Survived[testNaiveBayes$Pclass == "1"]), main="Original survived class 1",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$Pclass == "1"]), main="Predicted survived class 1",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Survived[testNaiveBayes$Pclass == "2"]), main="Original survived class 2",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$Pclass == "2"]), main="Predicted survived class 2",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Survived[testNaiveBayes$Pclass == "3"]), main="Original survived class 3",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$Pclass == "3"]), main="Predicted survived class 3",xlab="Survived",ylab="count")
```

```{r}
par(mfrow=c(2,2))
barplot(table(testNaiveBayes$Survived[testNaiveBayes$SibSp == "0"]), main="Original survived family members 0",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$SibSp == "0"]), main="Predicted survived family members 0",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Survived[testNaiveBayes$SibSp == "1"]), main="Original survived family members 1",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$SibSp == "1"]), main="Predicted survived family members 1",xlab="Survived",ylab="count")
```
```{r}
par(mfrow=c(2,2))
barplot(table(testNaiveBayes$Survived[testNaiveBayes$SibSp == "2"]), main="Original survived family members 2",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$SibSp == "2"]), main="Predicted survived family members 2",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Survived[testNaiveBayes$SibSp == "3"]), main="Original survived family members 3",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$SibSp == "3"]), main="Predicted survived family members 3",xlab="Survived",ylab="count")
```
```{r}
par(mfrow=c(2,2))
barplot(table(testNaiveBayes$Survived[testNaiveBayes$SibSp == "4"]), main="Original survived family members 4",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$SibSp == "4"]), main="Predicted survived family members 4",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Survived[testNaiveBayes$SibSp == "5"]), main="Original survived family members 5",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$SibSp == "5"]), main="Predicted survived family members 5",xlab="Survived",ylab="count")
```

```{r}
par(mfrow=c(1,2))
barplot(table(testNaiveBayes$Survived[testNaiveBayes$SibSp == "8"]), main="Original survived family members 8",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$SibSp == "8"]), main="Original survived family members 8",xlab="Survived",ylab="count")
```

```{r}
testNaiveBayes$Age[testNaiveBayes$Age<"19"]<- "<=18"
testNaiveBayes$Age[testNaiveBayes$Age>"65"]<- ">65"
testNaiveBayes$Age[(testNaiveBayes$Age>"18")&(testNaiveBayes$Age<"31")]<- ">18 and <=30"
testNaiveBayes$Age[(testNaiveBayes$Age>"30")&(testNaiveBayes$Age<"51")]<- ">30 and <=50"
testNaiveBayes$Age[(testNaiveBayes$Age>"50")&(testNaiveBayes$Age<"66")]<- ">50 and <=65"
```
```{r}
par(mfrow=c(2,2))
barplot(table(testNaiveBayes$Survived[testNaiveBayes$Age == "<=18"]), main="Original survived <=18 years",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$Age == "<=18"]), main="Predicted survived <= 18 years",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Survived[testNaiveBayes$Age == ">18 and <=30"]), main="Original survived >18 and <= 30 years",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$Age == ">18 and <=30"]), main="Predicted survived >18 and <= 30 years",xlab="Survived",ylab="count")
```
```{r}
par(mfrow=c(2,2))
barplot(table(testNaiveBayes$Survived[testNaiveBayes$Age == ">30 and <=50"]), main="Original survived >30 and <= 50 years",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$Age == ">30 and <=50"]), main="Predicted survived >30 and <= 50 years",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Survived[testNaiveBayes$Age == ">50 and <=65"]), main="Original survived >50 and <= 65 years",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$Age == ">50 and <=65"]), main="Predicted survived >50 and <= 65 years",xlab="Survived",ylab="count")
```
```{r}
par(mfrow=c(1,2))
barplot(table(testNaiveBayes$Survived[testNaiveBayes$Age == ">65"]), main="Original survived >65 years",xlab="Survived",ylab="count")
barplot(table(testNaiveBayes$Prediccio[testNaiveBayes$Age == ">65"]), main="Predicted survived >65 years",xlab="Survived",ylab="count")
```

<H4>Validació creuada</H4>

Un cop realitzat l'anàlisi de NaiveBayes, es pot pensar que el conjunt d'entrenament i test no era el més adequat per a realitzar el model. Per tant, es realitzarà un anàlisi de validació creuada per a obtenir un model més acurat a totes les dades existents. Un cop realitzada la validació creuada amb el mètode de NaiveBayes, s'obtenen els següents resultats, obtenint un model amb una predicció del 85.86%.

```{r include=FALSE}
library(caret)
library(groupdata2)
library(dplyr)
```
```{r}
set.seed(1989)
folds <- 10
dataNaiveBayes <- data
dataNaiveBayes$kfold <- sample(1:folds, nrow(dataNaiveBayes),replace=T)
Iter <- data.frame(iteracion=NULL,aciertos=NULL)
for (i in 1:folds)
{
  testFold <- subset(dataNaiveBayes, kfold==i)
  trainingFold <- subset(dataNaiveBayes, !kfold == i)
  mod <- naiveBayes(Survived ~ ., data = trainingFold)
  pre <- predict(mod, newdata = testFold)
  cm <- table(testFold$Survived, pre)
  precision <- (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] +cm[1,2] + cm[2,1])
  Iter <- rbind(Iter,data.frame(Iter=i,acierto=precision))
}
prom <- format(mean(Iter$acierto, na.rm=TRUE)*100,digits=4)
plot(Iter, type = "b", main="% Predicció en cada iteració model NaiveBayes",cex.axis=.7,
     cex.lab=.7, cex.main=.8,xlab="Nombre d'Iteracions",ylab="% Predicció")
abline(h=mean(Iter$acierto),col="blue",lty=2)
legend("topright",legend=paste("Eficiència de predicció=",prom,"%"),
       col="blue",lty=2,lwd=1,cex=.7, bg=NULL)
```

Un altre mètode per a realitzar la validació creuada pel mètode NaiveBayes, que dona un valor igual es:

```{r include=FALSE}
library(caret)
```
```{r}
set.seed(1989)
folds <- createFolds(dataNaiveBayes$Survived, k = 10)
cvNaiveBayes <- lapply(folds, function(x){
  training_fold <- dataNaiveBayes[-x, ]
  test_fold <- dataNaiveBayes[x, ]
  mod <- naiveBayes(Survived ~ ., data = training_fold)
  pre <- predict(mod, newdata = test_fold)
  cm <- table(test_fold$Survived, pre)
  precision <- (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] +cm[1,2] + cm[2,1])
  return(precision)
})
precisionNaiveBayes <- mean(as.numeric(cvNaiveBayes))
precisionNaiveBayes
```

Un cop realitzada la validació creuada pel model NaiveBayes, es realitza pel model d'arbre de classificació C50.
El resultat obtingut es el següent:

```{r include=FALSE}
library(caret)
library(groupdata2)
library(dplyr)
library(C50)
```
```{r}
set.seed(1989)
folds <- 10
dataC50 <- data
dataC50$kfold <- sample(1:folds, nrow(dataC50),replace=T)
vars<-c("Pclass","Sex","Age","SibSp","Parch","Fare")
str(dataC50[c(vars,"Survived")])
dataC50$Survived<-as.factor(dataC50$Survived)
Iter <- data.frame(iteracion=NULL,aciertos=NULL)
for (i in 1:folds)
{
  testFold <- subset(dataC50, kfold==i)
  trainingFold <- subset(dataC50, !kfold == i)
  mod <- C5.0(x=train[,vars],y=train$Survived)
  pre <- predict(mod, newdata = testFold)
  cm <- table(testFold$Survived, pre)
  precision <- (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] +cm[1,2] + cm[2,1])
  Iter <- rbind(Iter,data.frame(Iter=i,acierto=precision))
}
prom <- format(mean(Iter$acierto, na.rm=TRUE)*100,digits=4)
plot(Iter, type = "b", main="% Predicció en cada iteració model C50",cex.axis=.7,
     cex.lab=.7, cex.main=.8,xlab="Nombre d'Iteracions",ylab="% Predicció")
abline(h=mean(Iter$acierto),col="blue",lty=2)
legend("topright",legend=paste("Eficiència de predicció=",prom,"%"),
       col="blue",lty=2,lwd=1,cex=.7, bg=NULL)
```


Com es pot observar, l'eficiència del model d'arbre de classificació es major que la del classificador bayesià. Per tant, concluïm que, per al nostre conjunt de dades, el model més òptim es el model d'arbre de classificació.


<H3>5. Representació dels resultats a partir de taules i gràfiques.</H3>
Durant la resolució dels diferents apartats es van generant les taules i gràfiques necessàries per a la presentació dels resultats obtinguts.

<H3>6. Resolució del problema.A partir dels resultats obtinguts, quines són les conclusions? Els resultats permeten respondre al problema?</H3>

Un cop realitzat tot l'anàlisi, es pot assegurar que les variables necessàries per a predir si un passatger sobreviu o no són: Sex, Age, Pclass i SibSp. Es pot intuïr que efectivament té sentit que aquestes dades siguin les necessàries, ja que depenent de la edat tindrà més o menys possibilitats de sobreviure. Per una altra banda, si es va donar prioritat a les dones y nens, té sentit que el sexe sigui un factor determinant per a sobreviure. També, depenent de la classe la supervivència varia, ja que es dona proiritat a una classe o a una altra, al igual que al tamany de la família pot afectar. Per contra, variables com on va embarcar o la tarifa del bitllet es pot intuir que no tenen quasi rellevància en la supervivència de la persona.
 
Generant un model amb aquestes dades som capaços de predir, amb una exactitud del 87%, si un passatger sobreviu o no, utilitzant únicament les dades esmentades.

Per tant, com a conclusió, podem dir que s'ha aconseguit respondre a les preguntes inicials, que era estudiar quines variables tenen més impacte en la taxa de supervivència dels passatgers i, mitjançant aquestes, generar un model adequat per a predir qualsevol altre cas possible.

<H3>7. Codi</H3>
Es pot trobar el codi a la carpeta Code del github (https://github.com/Hakhaz/NetejaValidacioDades)


<table class="egt">

  <tr>

    CONTRIBUCIONS                 SIGNATURA
    Investigació prèvia           CPM, OFC
    Redacció de les respostes     CPM, OFC
    Desenvolupament codi          CPM, OFC

  </tr>

</table>